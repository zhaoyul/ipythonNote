{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.517208275438\n",
      "Error:0.0260702596931\n",
      "Error:0.0181554678526\n",
      "Error:0.0147234825688\n",
      "Error:0.0126993147791\n",
      "Error:0.0113272320733\n",
      "Error:0.0103192163347\n",
      "Error:0.00953860309535\n",
      "Error:0.00891115763147\n",
      "Error:0.00839264190064\n",
      "output after training:\n",
      "[[ 0.00966449]\n",
      " [ 0.00786506]\n",
      " [ 0.99358898]\n",
      " [ 0.99211957]]\n",
      "[[ 9.67299303]\n",
      " [-0.2078435 ]\n",
      " [-4.62963669]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#sigmoid funciton\n",
    "def sigmoidfunc(x, deriv = False):\n",
    "    if (deriv == True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "#input dataset\n",
    "x = np.array([[0, 0, 1],\n",
    "              [0, 1, 1],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 1]])\n",
    "#output dataset\n",
    "y = np.array([[0,0,1,1]]).T\n",
    "\n",
    "#seed random numbers to make calculation deterministic\n",
    "np.random.seed(1)\n",
    "\n",
    "#init weights rnadomly with mean 0\n",
    "weight0 = 2* np.random.random((3, 1)) - 1\n",
    "\n",
    "for iter in xrange(10000):\n",
    "    # forward propagation\n",
    "    layer0 = x\n",
    "    layer1 = sigmoidfunc(np.dot(l0, weight0))\n",
    "    \n",
    "    # cost function\n",
    "    layer1_error = y - layer1\n",
    "    \n",
    "    if (iter% 1000) == 0:\n",
    "        print \"Error:\" + str(np.mean(np.abs(layer1_error)))\n",
    "    \n",
    "    #mmultiply how nuch we missed by the slop of the sigmoid at the values of l1\n",
    "    layer1_delta = layer1_error * sigmoidfunc(layer1, True)\n",
    "    \n",
    "    #update weights\n",
    "    weight0 += np.dot(layer0.T, layer1_delta)\n",
    "    \n",
    "print \"output after training:\"\n",
    "print layer1\n",
    "print weight0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.517208275438\n",
      "Error:0.0260702596931\n",
      "Error:0.0181554678526\n",
      "Error:0.0147234825688\n",
      "Error:0.0126993147791\n",
      "Error:0.0113272320733\n",
      "Error:0.0103192163347\n",
      "Error:0.00953860309535\n",
      "Error:0.00891115763147\n",
      "Error:0.00839264190064\n",
      "output after training:\n",
      "[[ 0.00966449]\n",
      " [ 0.00786506]\n",
      " [ 0.99358898]\n",
      " [ 0.99211957]]\n",
      "[[ 9.67299303]\n",
      " [-0.2078435 ]\n",
      " [-4.62963669]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105bf7710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "errors = []\n",
    "\n",
    "#sigmoid funciton\n",
    "def sigmoidfunc(x, deriv = False):\n",
    "    if (deriv == True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "#input dataset\n",
    "x = np.array([[0, 0, 1],\n",
    "              [0, 1, 1],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 1]])\n",
    "#output dataset\n",
    "y = np.array([[0,0,1,1]]).T\n",
    "\n",
    "# x = np.array([[0, 0, 1],\n",
    "#               [1, 1, 1],\n",
    "#               [1, 0, 1],\n",
    "#               [0, 1, 1]])\n",
    "\n",
    "# y = np.array([[0, 0, 1, 1]]).T\n",
    "\n",
    "#seed random numbers to make calculation deterministic\n",
    "np.random.seed(1)\n",
    "\n",
    "#init weights rnadomly with mean 0\n",
    "weight0 = 2* np.random.random((3, 1)) - 1\n",
    "\n",
    "for iter in xrange(10000):\n",
    "    # forward propagation\n",
    "    layer0 = x\n",
    "    layer1 = sigmoidfunc(np.dot(l0, weight0))\n",
    "    \n",
    "    # cost function\n",
    "    layer1_error = y - layer1\n",
    "    \n",
    "    if (iter% 1000) == 0:\n",
    "        errors.append(np.mean(np.abs(layer1_error)))\n",
    "        print \"Error:\" + str(np.mean(np.abs(layer1_error)))\n",
    "    \n",
    "    #mmultiply how nuch we missed by the slop of the sigmoid at the values of l1\n",
    "    layer1_delta = layer1_error * sigmoidfunc(layer1, True)\n",
    "    \n",
    "    #update weights\n",
    "    weight0 += np.dot(layer0.T, layer1_delta)\n",
    "    \n",
    "print \"output after training:\"\n",
    "print layer1\n",
    "print weight0\n",
    "\n",
    "\n",
    "plt.plot(range(10), errors)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,10])\n",
    "axes.set_ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.496410031903\n",
      "Error:0.00858452565325\n",
      "Error:0.00578945986251\n",
      "Error:0.00462917677677\n",
      "Error:0.00395876528027\n",
      "Error:0.00351012256786\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "errors = []\n",
    "\n",
    "def nonlin(x,deriv=False):\n",
    "    if(deriv==True):\n",
    "        return x*(1-x)\n",
    "\n",
    "    return 1/(1+np.exp(-x))\n",
    "    \n",
    "X = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])\n",
    "                \n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# randomly initialize our weights with mean 0\n",
    "syn0 = 2*np.random.random((3,4)) - 1\n",
    "syn1 = 2*np.random.random((4,1)) - 1\n",
    "\n",
    "for j in xrange(60000):\n",
    "\n",
    "    # Feed forward through layers 0, 1, and 2\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0,syn0))\n",
    "    l2 = nonlin(np.dot(l1,syn1))\n",
    "\n",
    "    # how much did we miss the target value?\n",
    "    l2_error = y - l2\n",
    "    \n",
    "    if (j% 10000) == 0:\n",
    "        print \"Error:\" + str(np.mean(np.abs(l2_error)))\n",
    "        errors.append(np.mean(np.abs(l2_error)))\n",
    "\n",
    "        \n",
    "    # in what direction is the target value?\n",
    "    # were we really sure? if so, don't change too much.\n",
    "    l2_delta = l2_error*nonlin(l2,deriv=True)\n",
    "\n",
    "    # how much did each l1 value contribute to the l2 error (according to the weights)?\n",
    "    l1_error = l2_delta.dot(syn1.T)\n",
    "    \n",
    "    # in what direction is the target l1?\n",
    "    # were we really sure? if so, don't change too much.\n",
    "    l1_delta = l1_error * nonlin(l1,deriv=True)\n",
    "\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += l0.T.dot(l1_delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.dot?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
